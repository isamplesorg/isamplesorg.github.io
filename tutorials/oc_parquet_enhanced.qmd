---
title: OpenContext Parquet Data Analysis - Enhanced Edition
categories: [parquet, spatial, property-graph]
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
---

This document provides an enhanced analysis of the OpenContext iSamples parquet file, demonstrating the property graph structure and how to work with archaeological specimen data.

## Understanding the Property Graph Structure

The OpenContext iSamples parquet file implements a sophisticated property graph model that combines the flexibility of graph databases with the analytical performance of columnar storage. Unlike traditional relational databases or pure graph databases, this approach stores both entities (nodes) and relationships (edges) in a single table structure.

### Why a Property Graph?

Archaeological and specimen data inherently forms a network:

- **Samples** are collected at **sites** during **events**
- **Sites** have **geographic locations**
- **Samples** have **material types** from controlled vocabularies
- **People** (agents) have various **roles** in the collection process

This interconnected nature makes a graph model ideal for representing the complex relationships while maintaining query performance.

## Setup

```{ojs}
//| output: false
// Import DuckDB for browser-based SQL analysis
import { DuckDBClient } from "https://cdn.jsdelivr.net/npm/@observablehq/duckdb@latest/+esm"
```

```{ojs}
//| echo: false
viewof parquet_path = Inputs.text({
    label: "Parquet File URL",
    value: "https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg.parquet",
    width: "100%",
    submit: true
});
```

```{ojs}
// Create a DuckDB instance and load the parquet file
db = {
    const instance = await DuckDBClient.of();
    await instance.query(`CREATE VIEW nodes AS SELECT * FROM read_parquet('${parquet_path}')`);
    return instance;
}

// Helper function for loading data with visual feedback
async function loadData(query, params=[], waiting_id=null) {
    const waiter = document.getElementById(waiting_id);
    if (waiter) {
        waiter.hidden = false;
    }
    try {
        const _results = await db.query(query, ...params);
        return _results;
    } catch (error) {
        if (waiter) {
            waiter.innerHTML = `<pre>${error}</pre>`;
        }
        return null;
    } finally {
        if (waiter) {
            waiter.hidden = true;
        }
    }
}
```

## Data Model Deep Dive

### Entity Types in the Dataset

The parquet file contains 7 distinct object types (`otype`), each serving a specific purpose in the archaeological data model:

```{ojs}
entityTypeDescriptions = {
    return [
        {otype: "_edge_", purpose: "Relationships between entities", icon: "üîó"},
        {otype: "MaterialSampleRecord", purpose: "Physical samples/specimens", icon: "ü™®"},
        {otype: "SamplingEvent", purpose: "When/how samples were collected", icon: "üìÖ"},
        {otype: "GeospatialCoordLocation", purpose: "Geographic coordinates", icon: "üìç"},
        {otype: "SamplingSite", purpose: "Archaeological sites/dig locations", icon: "üèõÔ∏è"},
        {otype: "IdentifiedConcept", purpose: "Controlled vocabulary terms", icon: "üìö"},
        {otype: "Agent", purpose: "People and organizations", icon: "üë§"}
    ];
}

viewof entityTypeTable = Inputs.table(entityTypeDescriptions, {
    header: {
        otype: "Entity Type",
        purpose: "Purpose",
        icon: "Icon"
    }
})
```

### Entity Distribution

```{ojs}
entityStats = {
    const query = `
        SELECT
            otype,
            COUNT(*) as count,
            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage
        FROM nodes
        GROUP BY otype
        ORDER BY count DESC
    `;
    const data = await loadData(query, [], "loading_entity_stats");
    return data;
}
```

<div id="loading_entity_stats" hidden>Loading entity statistics...</div>

```{ojs}
viewof entityStatsTable = Inputs.table(entityStats, {
    header: {
        otype: "Entity Type",
        count: "Count",
        percentage: "Percentage"
    },
    format: {
        count: d => d.toLocaleString(),
        percentage: d => d + "%"
    }
})
```

Total records: ${entityStats.reduce((sum, row) => sum + row.count, 0).toLocaleString()}

### How Entities Connect: The Edge Model

Edges use a triple structure inspired by RDF:

- **Subject (s)**: The source entity's `row_id`
- **Predicate (p)**: The relationship type
- **Object (o)**: Array of target entity `row_id`s

This allows representing both simple (1:1) and complex (1:many) relationships efficiently.

```{ojs}
// Visualize common relationship patterns
relationshipPatterns = {
    const query = `
        SELECT
            p as relationship,
            COUNT(*) as usage_count,
            COUNT(DISTINCT s) as unique_subjects
        FROM nodes
        WHERE otype = '_edge_'
          AND p IS NOT NULL
        GROUP BY p
        ORDER BY usage_count DESC
        LIMIT 15
    `;
    const data = await loadData(query, [], "loading_relationships");
    return data;
}
```

<div id="loading_relationships" hidden>Loading relationship patterns...</div>

```{ojs}
viewof relationshipTable = Inputs.table(relationshipPatterns, {
    header: {
        relationship: "Relationship Type",
        usage_count: "Total Uses",
        unique_subjects: "Unique Subjects"
    },
    format: {
        usage_count: d => d.toLocaleString(),
        unique_subjects: d => d.toLocaleString()
    }
})
```

## Working with the Graph: Query Patterns

### Finding Samples with Locations

The most common need is connecting samples to their geographic coordinates. This requires traversing the graph through edges:

```{ojs}
// Example: Get samples with direct location assignments (CORRECTED)
// Path: Sample -> produced_by -> SamplingEvent -> sample_location -> GeospatialCoordLocation
sampleLocationExample = {
    const query = `
        WITH sample_locations AS (
            SELECT
                s.pid as sample_id,
                s.label as sample_label,
                g.latitude,
                g.longitude,
                'direct_event_location' as location_relationship
            FROM nodes s
            JOIN nodes e1 ON s.row_id = e1.s AND e1.p = 'produced_by'
            JOIN nodes event ON e1.o[1] = event.row_id
            JOIN nodes e2 ON event.row_id = e2.s AND e2.p = 'sample_location'
            JOIN nodes g ON e2.o[1] = g.row_id
            WHERE s.otype = 'MaterialSampleRecord'
              AND event.otype = 'SamplingEvent'
              AND g.otype = 'GeospatialCoordLocation'
              AND g.latitude IS NOT NULL
            LIMIT 5
        )
        SELECT * FROM sample_locations
    `;
    const data = await loadData(query, [], "loading_sample_loc_example");
    return data;
}
```

<div id="loading_sample_loc_example" hidden>Loading example...</div>

```{ojs}
viewof sampleLocationTable = Inputs.table(sampleLocationExample, {
    layout: "auto"
})
```

### Multi-Hop Traversal: Sample ‚Üí Event ‚Üí Site ‚Üí Location

Many samples don't have direct coordinates but are linked through their collection event and site:

```{ojs}
// Trace the full chain from sample to site location
siteChainExample = {
    const query = `
        SELECT
            samp.pid as sample_id,
            event.pid as event_id,
            site.label as site_name,
            loc.latitude,
            loc.longitude
        FROM nodes samp
        JOIN nodes e1 ON samp.row_id = e1.s AND e1.p = 'produced_by'
        JOIN nodes event ON e1.o[1] = event.row_id
        JOIN nodes e2 ON event.row_id = e2.s AND e2.p = 'sampling_site'
        JOIN nodes site ON e2.o[1] = site.row_id
        JOIN nodes e3 ON site.row_id = e3.s AND e3.p = 'site_location'
        JOIN nodes loc ON e3.o[1] = loc.row_id
        WHERE samp.otype = 'MaterialSampleRecord'
          AND event.otype = 'SamplingEvent'
          AND site.otype = 'SamplingSite'
          AND loc.otype = 'GeospatialCoordLocation'
        LIMIT 5
    `;
    const data = await loadData(query, [], "loading_chain_example");
    return data;
}
```

<div id="loading_chain_example" hidden>Loading traversal example...</div>

```{ojs}
viewof siteChainTable = Inputs.table(siteChainExample, {
    layout: "auto",
    width: {
        sample_id: 150,
        event_id: 150,
        site_name: 200
    }
})
```

## Site Analysis

### Top Archaeological Sites by Sample Count

```{ojs}
topSites = {
    const query = `
        WITH site_samples AS (
            SELECT
                site.label as site_name,
                site.pid as site_id,
                COUNT(DISTINCT samp.row_id) as sample_count
            FROM nodes samp
            JOIN nodes e1 ON samp.row_id = e1.s AND e1.p = 'produced_by'
            JOIN nodes event ON e1.o[1] = event.row_id
            JOIN nodes e2 ON event.row_id = e2.s AND e2.p = 'sampling_site'
            JOIN nodes site ON e2.o[1] = site.row_id
            WHERE samp.otype = 'MaterialSampleRecord'
              AND event.otype = 'SamplingEvent'
              AND site.otype = 'SamplingSite'
            GROUP BY site.label, site.pid
        )
        SELECT * FROM site_samples
        ORDER BY sample_count DESC
        LIMIT 20
    `;
    const data = await loadData(query, [], "loading_top_sites");
    return data;
}
```

<div id="loading_top_sites" hidden>Loading site statistics...</div>

```{ojs}
viewof topSitesTable = Inputs.table(topSites, {
    header: {
        site_name: "Site Name",
        site_id: "Site ID",
        sample_count: "Sample Count"
    },
    format: {
        sample_count: d => d.toLocaleString()
    }
})
```

## Material Analysis

### Material Type Distribution

Understanding what types of materials are found across the dataset:

```{ojs}
materialTypes = {
    const query = `
        SELECT
            mat.label as material_type,
            mat.name as category,
            COUNT(DISTINCT samp.row_id) as sample_count
        FROM nodes samp
        JOIN nodes e ON samp.row_id = e.s AND e.p = 'has_material_category'
        JOIN nodes mat ON e.o[1] = mat.row_id
        WHERE samp.otype = 'MaterialSampleRecord'
          AND e.otype = '_edge_'
          AND mat.otype = 'IdentifiedConcept'
        GROUP BY mat.label, mat.name
        ORDER BY sample_count DESC
        LIMIT 30
    `;
    const data = await loadData(query, [], "loading_materials");
    return data;
}
```

<div id="loading_materials" hidden>Analyzing materials...</div>

```{ojs}
viewof materialTable = Inputs.table(materialTypes, {
    header: {
        material_type: "Material Type",
        category: "Category",
        sample_count: "Sample Count"
    },
    format: {
        sample_count: d => d.toLocaleString()
    }
})
```

## Spatial Distribution

### Geographic Coverage

```{ojs}
spatialStats = {
    const query = `
        WITH coord_stats AS (
            SELECT
                MIN(latitude) as min_lat,
                MAX(latitude) as max_lat,
                MIN(longitude) as min_lon,
                MAX(longitude) as max_lon,
                AVG(latitude) as avg_lat,
                AVG(longitude) as avg_lon,
                COUNT(*) as total_locations,
                COUNT(CASE WHEN obfuscated THEN 1 END) as obfuscated_count
            FROM nodes
            WHERE otype = 'GeospatialCoordLocation'
              AND latitude IS NOT NULL
              AND longitude IS NOT NULL
        )
        SELECT * FROM coord_stats
    `;
    const data = await loadData(query, [], "loading_spatial");
    return data;
}
```

<div id="loading_spatial" hidden>Loading spatial statistics...</div>

```{ojs}
viewof spatialDisplay = {
    const stats = spatialStats[0];
    return html`<div style="padding: 1rem; background: #f0f9ff; border-radius: 8px;">
        <h4 style="margin-top: 0;">Geographic Coverage</h4>
        <p>Total locations: <strong>${stats.total_locations.toLocaleString()}</strong></p>
        <p>Obfuscated locations: <strong>${stats.obfuscated_count.toLocaleString()}</strong>
           (${(stats.obfuscated_count / stats.total_locations * 100).toFixed(1)}%)</p>
        <p>Latitude range: <strong>${stats.min_lat.toFixed(2)}¬∞ to ${stats.max_lat.toFixed(2)}¬∞</strong></p>
        <p>Longitude range: <strong>${stats.min_lon.toFixed(2)}¬∞ to ${stats.max_lon.toFixed(2)}¬∞</strong></p>
        <p>Center point: <strong>${stats.avg_lat.toFixed(2)}¬∞, ${stats.avg_lon.toFixed(2)}¬∞</strong></p>
    </div>`;
}
```

### Handling Sensitive Location Data

Archaeological sites often require location protection:

```{ojs}
obfuscationStats = {
    const query = `
        SELECT
            obfuscated,
            COUNT(*) as location_count,
            AVG(CASE WHEN latitude IS NOT NULL THEN 1 ELSE 0 END) * 100 as pct_with_coords
        FROM nodes
        WHERE otype = 'GeospatialCoordLocation'
        GROUP BY obfuscated
    `;
    const data = await loadData(query, [], "loading_obfusc_stats");
    return data;
}
```

<div id="loading_obfusc_stats" hidden>Analyzing location sensitivity...</div>

```{ojs}
viewof obfuscationTable = Inputs.table(obfuscationStats, {
    header: {
        obfuscated: "Location Protection",
        location_count: "Count",
        pct_with_coords: "% With Coordinates"
    },
    format: {
        obfuscated: d => d ? "üîí Protected" : "üìç Precise",
        location_count: d => d.toLocaleString(),
        pct_with_coords: d => d.toFixed(1) + "%"
    }
})
```

::: {.callout-important}
## Data Usage Note
When visualizing archaeological data, always respect location sensitivity flags. Obfuscated coordinates are intentionally imprecise to protect archaeological sites from looting.
:::

## Performance & Optimization Strategies

### Query Performance Guidelines

When working with this 11.6M row dataset:

1. **Filter Early**: Always apply `otype` filters first
   ```sql
   -- Good: Reduces to ~1M rows immediately
   WHERE otype = 'MaterialSampleRecord'

   -- Avoid: Scans all 11M rows
   WHERE label LIKE '%pottery%'
   ```

2. **Use Views for Complex Patterns**: Pre-compute common joins
   ```sql
   CREATE VIEW samples_with_coords AS
   SELECT ... -- complex join query
   ```

3. **Leverage DuckDB's Columnar Format**: Aggregate before detailed analysis

### Data Loading Strategies

For web applications:

```{ojs}
// Progressive loading pattern for large datasets
progressiveLoadExample = {
    // Start with aggregated overview
    const overview = await db.query(`
        SELECT
            ROUND(latitude/10)*10 as lat_bucket,
            ROUND(longitude/10)*10 as lon_bucket,
            COUNT(*) as point_count
        FROM nodes
        WHERE otype = 'GeospatialCoordLocation'
          AND latitude IS NOT NULL
        GROUP BY lat_bucket, lon_bucket
    `);

    return {
        strategy: "Progressive Loading",
        initial_points: overview.length,
        full_dataset: 198433,
        reduction_factor: Math.round(198433 / overview.length)
    };
}
```

```{ojs}
viewof loadStrategyDisplay = {
    const stats = await progressiveLoadExample;
    return html`<div style="padding: 1rem; background: #e0f2fe; border-radius: 8px;">
        <h4 style="margin-top: 0;">Loading Strategy Impact</h4>
        <p>Initial load: <strong>${stats.initial_points.toLocaleString()}</strong> aggregated points</p>
        <p>Full dataset: <strong>${stats.full_dataset.toLocaleString()}</strong> individual locations</p>
        <p>Reduction factor: <strong>${stats.reduction_factor}x</strong> faster initial load</p>
    </div>`;
}
```

## Data Quality Metrics

```{ojs}
dataQuality = {
    const query = `
        WITH quality_checks AS (
            SELECT
                'Total Rows' as metric,
                COUNT(*) as value
            FROM nodes

            UNION ALL

            SELECT
                'Unique PIDs' as metric,
                COUNT(DISTINCT pid) as value
            FROM nodes

            UNION ALL

            SELECT
                'Samples with Direct Location' as metric,
                COUNT(DISTINCT s.row_id) as value
            FROM nodes s
            JOIN nodes e ON s.row_id = e.s AND e.p = 'sample_location'
            WHERE s.otype = 'MaterialSampleRecord'

            UNION ALL

            SELECT
                'Samples with Site Location' as metric,
                COUNT(DISTINCT s.row_id) as value
            FROM nodes s
            JOIN nodes e ON s.row_id = e.s AND e.p = 'produced_by'
            WHERE s.otype = 'MaterialSampleRecord'
        )
        SELECT * FROM quality_checks
    `;
    const data = await loadData(query, [], "loading_quality");
    return data;
}
```

<div id="loading_quality" hidden>Checking data quality...</div>

```{ojs}
viewof qualityTable = Inputs.table(dataQuality, {
    header: {
        metric: "Quality Metric",
        value: "Count"
    },
    format: {
        value: d => d.toLocaleString()
    }
})
```

## Summary

This property graph structure enables:

- **Flexible relationships** between archaeological entities
- **Efficient queries** through DuckDB's columnar storage
- **Complex traversals** to connect samples with locations, events, and metadata
- **Scalable analysis** of 11.6M records with reasonable performance

The key to working with this data is understanding the graph structure and using appropriate JOIN patterns to traverse relationships between entities.